{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "import random\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1= pd.read_csv(\"G:/Goldman Sachs/Bond Liquidity Prediction/ML_Bond_metadata.csv\")\n",
    "df2=pd.read_csv(\"G:/Goldman Sachs/Bond Liquidity Prediction/sell.csv\")\n",
    "df3=pd.read_csv(\"G:/Goldman Sachs/Bond Liquidity Prediction/buy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.rename(columns={'isin': 'id'}, inplace=True)\n",
    "df1['amtIssued']= np.sqrt(np.log(df1['amtIssued']))\n",
    "df1['amtOutstanding']= np.sqrt(np.log(df1['amtOutstanding']))\n",
    "df1.issueDate.replace(np.NaN,-1,inplace=True)\n",
    "df1.maturity.replace(np.NaN,-1,inplace= True)\n",
    "df1.issueDate=pd.to_datetime(df1.issueDate)\n",
    "df1.maturity=pd.to_datetime(df1.maturity)\n",
    "df1['issue_year']=df1.issueDate.dt.year\n",
    "df1['issue_month']=df1.issueDate.dt.month\n",
    "df1['issue_day']=df1.issueDate.dt.dayofweek\n",
    "df1['maturity_year']=df1.maturity.dt.year\n",
    "df1['maturity_month']=df1.maturity.dt.month\n",
    "df1['maturity_day']=df1.maturity.dt.dayofweek\n",
    "df1.couponFrequency.replace(np.NaN, -1,inplace= 1)\n",
    "df1.ratingAgency1EffectiveDate.replace(np.NaN,-1,inplace=True)\n",
    "df1.ratingAgency2EffectiveDate.replace(np.NaN,-1,inplace= True)\n",
    "df1.ratingAgency1EffectiveDate=pd.to_datetime(df1.ratingAgency1EffectiveDate)\n",
    "df1.ratingAgency2EffectiveDate=pd.to_datetime(df1.ratingAgency2EffectiveDate)\n",
    "df1['ratingAgency1_year']=df1.ratingAgency1EffectiveDate.dt.year\n",
    "df1['ratingAgency1_month']=df1.ratingAgency1EffectiveDate.dt.month\n",
    "df1['ratingAgency1_day']=df1.ratingAgency1EffectiveDate.dt.dayofweek\n",
    "df1['ratingAgency2_year']=df1.ratingAgency2EffectiveDate.dt.year\n",
    "df1['ratingAgency2_month']=df1.ratingAgency2EffectiveDate.dt.month\n",
    "df1['ratingAgency2_day']=df1.ratingAgency2EffectiveDate.dt.dayofweek\n",
    "df1['Day_differ']=df1.maturity-df1.issueDate\n",
    "df1['Day_differ']=(df1.Day_differ/np.timedelta64(1,'D')).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in ['market','collateralType','couponType','industryGroup','industrySector','industrySubgroup','maturityType','securityType','paymentRank','ratingAgency1Rating','ratingAgency1Watch','ratingAgency2Rating','ratingAgency2Watch']:\n",
    "    dummies = pd.get_dummies(df1[column])\n",
    "    df1[dummies.columns] = dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.drop(['issueDate','market','collateralType','couponType','industryGroup','industrySector','industrySubgroup','maturity','maturityType','securityType','paymentRank','ratingAgency1Rating','ratingAgency1Watch','ratingAgency2Rating','ratingAgency2Watch','ratingAgency1EffectiveDate','ratingAgency2EffectiveDate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.rename(columns={'144aFlag': 'Flag'}, inplace=True)\n",
    "df1.Flag.replace('flag0',0,inplace= 1)\n",
    "df1.Flag.replace('flag1',1,inplace= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.drop(['side','date','time'],axis=1, inplace=True)\n",
    "df3['buyvolume']= np.sqrt(np.log(df3['buyvolume']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.Day.replace({'Mon' : 1, 'Tue' : 2, 'Wed': 3, 'Thu': 4, 'Fri': 5},inplace=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_buy= pd.merge(df3, df1, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID_col=['id']\n",
    "target_col=['buyvolume']\n",
    "cat_col=['issuer']\n",
    "features=list(set(list(train_buy.columns))-set(ID_col)-set(target_col)-set(cat_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_10= pd.read_csv(\"G:/Goldman Sachs/Bond Liquidity Prediction/test_10jun2016.csv\")\n",
    "test_13=pd.read_csv(\"G:/Goldman Sachs/Bond Liquidity Prediction/test_13jun2016.csv\")\n",
    "test_14=pd.read_csv(\"G:/Goldman Sachs/Bond Liquidity Prediction/test_14jun2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv=[]\n",
    "lst=[]\n",
    "kf=cross_validation.KFold(len(train_buy),n_folds=3,random_state=0)\n",
    "for idx1,idx2 in kf:\n",
    "    x_train,x_cv=train_buy[features].iloc[idx1],train_buy[features].iloc[idx2]\n",
    "    y_train,y_cv=train_buy.buyvolume.iloc[idx1],train_buy.buyvolume.iloc[idx2]\n",
    "    random.seed(100)\n",
    "    rf =GradientBoostingRegressor()\n",
    "    rf.fit(x_train, y_train)\n",
    "    cv.extend(rf.predict(x_cv))\n",
    "    lst.append(rf.predict(test_10[features]))\n",
    "    print(metrics.mean_squared_error(rf.predict(x_cv),y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred1_10jun_buy=pd.DataFrame({'id': test_10.id, 'buyvolume_10':np.average(lst,axis=0)})\n",
    "pred1_10jun_buy_cv=pd.DataFrame({'id': train_buy.id,'buyvolume_10': cv})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred1_10jun_buy.buyvolume_10=np.exp(np.power(pred1_10jun_buy.buyvolume_10,2))\n",
    "pred1_10jun_buy.to_csv(\"C:/Users/Rajat/Desktop/GB_10jun_buyvolume.csv\",index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred1_10jun_buy_cv.buyvolume_10=np.exp(np.power(pred1_10jun_buy_cv.buyvolume_10,2))\n",
    "pred1_10jun_buy_cv.to_csv(\"C:/Users/Rajat/Desktop/GB_10jun_buyvolume_cv.csv\",index= False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
